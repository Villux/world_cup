{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error, accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from features.data_provider import get_train_and_test_dataset, get_feature_columns, get_whole_dataset\n",
    "from simulation.predictor import ScorePredictor, MaxProbabilityScorePredictor\n",
    "from simulation.simulation import run_simulation\n",
    "from models.grid_search import run_custom_grid_search\n",
    "from models.score_model import get_model\n",
    "from models.helpers import get_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = get_train_and_test_dataset(\"home_score\")\n",
    "away = get_train_and_test_dataset(\"away_score\")\n",
    "\n",
    "X_train = pd.concat([home[0], away[0]])\n",
    "y_train = pd.concat([home[1], away[1]])\n",
    "\n",
    "X_test = pd.concat([home[2], away[2]])\n",
    "y_test = pd.concat([home[3], away[3]])\n",
    "\n",
    "X_test_home = home[2]\n",
    "X_test_away = away[2]\n",
    "\n",
    "_, _, _, true_outcomes = get_train_and_test_dataset(\"home_win\")\n",
    "\n",
    "def get_best_params(results, verbose=False):\n",
    "    best_params_acc = results.loc[results['test_acc'].idxmax(), [\"max_depth\", \"max_features\", \"min_samples_leaf\"]]\n",
    "    best_params_logloss = results.loc[results['test_logloss'].idxmin(), [\"max_depth\", \"max_features\", \"min_samples_leaf\"]]\n",
    "     \n",
    "    best_params_acc = best_params_acc.replace({np.nan:None})\n",
    "    best_params_logloss = best_params_logloss.replace({np.nan:None})\n",
    "    return best_params_acc.to_dict(), best_params_logloss.to_dict()\n",
    "\n",
    "def get_model_accuracy(params):\n",
    "    predicted_outcomes = []\n",
    "    predicted_outcome_probabilities = []\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    res = {\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "        \"max_features\": params[\"max_features\"],\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "    }\n",
    "\n",
    "    for i in range(X_test_home.shape[0]):\n",
    "        home_fv = [X_test_home.iloc[i].as_matrix()]\n",
    "        away_fv = [X_test_away.iloc[i].as_matrix()]\n",
    "        home_mu = model.predict(home_fv)\n",
    "        away_mu = model.predict(away_fv)\n",
    "\n",
    "        goal_matrix = ScorePredictor.get_goal_matrix(home_mu, away_mu)\n",
    "        away_win, draw, home_win = ScorePredictor.get_outcome_probabilities(goal_matrix)\n",
    "\n",
    "        if home_win > away_win and home_win > draw:\n",
    "            outcome = 1\n",
    "        elif away_win > home_win and away_win > draw:\n",
    "            outcome = -1\n",
    "        elif draw > home_win and draw > away_win:\n",
    "            outcome = 0                \n",
    "        else:\n",
    "            print(\"IDENTICAL PROBABILITIES\", away_win, draw, home_win)\n",
    "            outcome = 1\n",
    "        predicted_outcomes.append(outcome)\n",
    "        predicted_outcome_probabilities.append([away_win, draw, home_win])\n",
    "\n",
    "    res[\"test_acc\"] = accuracy_score(true_outcomes.values, predicted_outcomes)\n",
    "    res[\"test_mae\"] = mean_absolute_error(true_outcomes.values, predicted_outcomes)\n",
    "    res[\"test_mse\"] = mean_squared_error(true_outcomes.values, predicted_outcomes)\n",
    "    res[\"test_logloss\"] = log_loss(true_outcomes.values, np.array(predicted_outcome_probabilities))\n",
    "\n",
    "    return res\n",
    "\n",
    "def run_custom_grid_search(org_params):\n",
    "    start = time()\n",
    "\n",
    "    results = []\n",
    "    param_array = []\n",
    "    for depth in [3, 5, 8, 12, None]:\n",
    "        for min_samples in [1, 3, 5, 10, 15]:\n",
    "            for max_features in [\"sqrt\", \"log2\"]:\n",
    "                params = org_params.copy()\n",
    "                params[\"max_depth\"] = depth\n",
    "                params[\"min_samples_leaf\"] = min_samples\n",
    "                params[\"max_features\"] = max_features\n",
    "                param_array.append(params)\n",
    "    \n",
    "    \n",
    "    pool = Pool(cpu_count())\n",
    "    results = pool.map(get_model_accuracy, param_array)\n",
    "    print(\"Parameter estimation took: \", time() - start)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"oob_score\":True, \"bootstrap\":True, \"n_estimators\": 5000} \n",
    "results = run_custom_grid_search(params)\n",
    "get_best_params(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'max_depth': 8.0, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
    "params.pop(\"n_estimators\", None)\n",
    "params.update(best_params)\n",
    "\n",
    "n_estimators = [200, 500, 1000, 2000, 5000]\n",
    "param_array = []\n",
    "for k in n_estimators:\n",
    "    k_params = params.copy()\n",
    "    k_params[\"n_estimators\"] = k\n",
    "    param_array.append(params)\n",
    "\n",
    "param_array = param_array * 10 # run 10 times\n",
    "pool = Pool(cpu_count())\n",
    "#results = pool.map(get_model_accuracy, param_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
